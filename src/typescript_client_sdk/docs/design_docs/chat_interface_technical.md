# Chat Interface Technical Addendum - SDK Integration Guide

## Executive Summary

This technical addendum provides corrections and clarifications to the chat interface design document, ensuring accurate SDK integration patterns. The document addresses authentication flow, WebSocket connection establishment, session management, and proper usage of SDK hooks.

## Critical Technical Corrections

### 1. Authentication Flow - No useAuth Hook

**Design Assumption:** Uses `useAuth()` hook for user information  
**Reality:** Authentication is handled separately before SDK initialization

#### Actual Authentication Flow:

```typescript
// 1. Login via API (packages/demo/src/lib/auth.ts)
const loginResponse = await login({
  username: 'user',
  password: 'pass'
});

// loginResponse contains:
{
  agent_c_token: string,       // JWT for WebSocket auth
  heygen_token: string,        // For avatar sessions
  ui_session_id: string,       // Session ID for WebSocket
  user: {
    user_id: string,
    user_name: string,
    email: string,
    // ... other user fields
  },
  voices: Voice[],             // Available voices
  avatars: Avatar[],           // Available avatars
  agents: Agent[]              // Available agents
}

// 2. Store tokens in cookies (handled by auth.ts)
// 3. Pass token and session_id to RealtimeClient during initialization
```

#### User Display Component Correction:

```typescript
// UserDisplay.tsx - Get user from login response, not SDK hook
import { getCurrentUser } from '@/lib/auth'; // Not from SDK

const UserDisplay = () => {
  const user = getCurrentUser(); // Parses JWT for user info

  return (
    <div className="user-info">
      {/* Display user.sub (username) from JWT */}
      <span>{user?.sub || 'Unknown User'}</span>
    </div>
  );
};
```

### 2. WebSocket Connection Establishment

**Design Assumption:** WebSocket connects automatically when arriving from login  
**Reality:** Explicit initialization required with auth token and ui_session_id

#### Correct Connection Pattern:

```typescript
// ChatPage.tsx - Initialize SDK with auth data
import { RealtimeClient } from '@agentc/realtime-core';
import { AgentCProvider } from '@agentc/realtime-react';
import { getToken, getSessionInfo } from '@/lib/auth';

export function ChatPage() {
  const [client, setClient] = useState<RealtimeClient | null>(null);

  useEffect(() => {
    const initializeClient = async () => {
      // Get auth token from cookies
      const authToken = getToken();
      if (!authToken) {
        router.push('/login');
        return;
      }

      // Get session info from login response
      const sessionInfo = await getSessionInfo();

      // Create client with auth
      const realtimeClient = new RealtimeClient({
        apiUrl: process.env.NEXT_PUBLIC_WS_URL || 'ws://localhost:8000/ws/v1',
        authToken: authToken,              // JWT from login
        sessionId: sessionInfo.ui_session_id, // From login response
        enableAudio: true,
        enableTurnManager: true,
        audioConfig: {
          enableInput: true,
          enableOutput: true,
          respectTurnState: true
        }
      });

      // Connect to WebSocket
      await realtimeClient.connect();
      setClient(realtimeClient);
    };

    initializeClient();

    return () => {
      client?.disconnect();
      client?.destroy();
    };
  }, []);

  // Wrap app in provider with initialized client
  if (!client) return <LoadingScreen />;

  return (
    <AgentCProvider client={client}>
      <ChatInterface />
    </AgentCProvider>
  );
}
```

### 3. UI Session Lifecycle

**Design Assumption:** SDK creates a "ui_session" with backend  
**Reality:** ui_session_id comes from login response, represents entire user session

#### UI Session Clarification:

- **ui_session_id**: Generated by backend during login, represents user's entire session
- **chat_session_id**: Individual conversation sessions within the UI session
- One ui_session can have multiple chat_sessions

```typescript
// Session hierarchy:
ui_session_id (from login)
  └── chat_session_1
  └── chat_session_2
  └── chat_session_3 (current)
```

### 4. Available SDK Hooks vs Design Assumptions

#### Actually Available Hooks:

```typescript
// From @agentc/realtime-react
import {
  useRealtimeClient,    // Direct client access
  useConnection,        // Connection state & stats
  useAudio,            // Audio control with turn awareness
  useChat,             // Message history & text sending
  useTurnState,        // Turn management state
  useVoiceModel,       // Voice selection
  useAvatar            // Avatar session management
} from '@agentc/realtime-react';
```

#### NOT Available (Design Assumptions):

```typescript
// ❌ These don't exist:
useAuth()           // Auth handled separately via auth.ts
useSessionName()    // Part of useChat hook
useOutputMode()     // Should be managed in UI state
```

### 5. Avatar Integration - Correct Flow

**Design Assumption:** Avatar "just works" when selected  
**Reality:** Complex handshake with HeyGen required

#### Actual Avatar Integration:

```typescript
// AvatarDisplayView.tsx - Correct implementation
import { useAvatar } from '@agentc/realtime-react';
import StreamingAvatar from '@heygen/streaming-avatar';

const AvatarDisplayView = () => {
  const { 
    initializeAvatar,
    terminateAvatar,
    avatarSession 
  } = useAvatar();

  const client = useRealtimeClient();
  const [heygenAvatar, setHeygenAvatar] = useState(null);

  // Initialize HeyGen session
  const startAvatarSession = async (avatarId: string) => {
    // 1. Get HeyGen token from auth
    const heygenToken = getHeyGenToken(); // From auth.ts

    // 2. Create HeyGen streaming avatar instance
    const avatar = new StreamingAvatar({ token: heygenToken });

    // 3. Create session with HeyGen
    await avatar.createStartAvatar({
      avatarName: avatarId,
      quality: 'high',
      voice: { voiceId: 'avatar' } // Special voice mode
    });

    // 4. Wait for STREAM_READY event from HeyGen
    avatar.on('stream-ready', (event) => {
      // 5. CRITICAL: Notify Agent C of avatar session
      client.setAvatarSession(event.sessionId, avatarId);

      // 6. Attach stream to video element
      if (videoRef.current && event.stream) {
        videoRef.current.srcObject = event.stream;
      }
    });

    setHeygenAvatar(avatar);
  };

  // Agent C automatically routes audio through avatar when session is set
  // No PCM streaming occurs - HeyGen handles all audio
};
```

### 6. Output Mode Management

**Design Assumption:** OutputSelector directly controls SDK behavior  
**Reality:** OutputSelector should update voice model, which affects SDK routing

#### Correct Output Mode Implementation:

```typescript
// OutputModeManager.tsx
const OutputModeManager = () => {
  const { setVoiceModel, availableVoices } = useVoiceModel();
  const { initializeAvatar, terminateAvatar } = useAvatar();
  const [outputMode, setOutputMode] = useState<'chat' | 'avatar' | 'voice'>('chat');

  const handleOutputModeChange = async (option: OutputOption) => {
    // Clean up previous mode
    if (outputMode === 'avatar') {
      await terminateAvatar();
    }

    switch (option.type) {
      case 'text':
        // Set voice to 'none' - text only mode
        setVoiceModel('none');
        setOutputMode('chat');
        break;

      case 'voice':
        // Set specific voice for audio streaming
        setVoiceModel(option.metadata.voiceId);
        setOutputMode('voice');
        break;

      case 'avatar':
        // Initialize avatar session
        await initializeAvatar(option.metadata.avatarId);
        // Voice automatically switches to 'avatar' mode when session is set
        setOutputMode('avatar');
        break;
    }
  };

  return (
    <OutputSelector
      selectedOption={currentOption}
      onOptionSelect={handleOutputModeChange}
      voiceOptions={availableVoices}
      avatarOptions={avatarsFromLogin}
    />
  );
};
```

### 7. Turn Management Integration

**Design Assumption:** Turn management is separate from audio  
**Reality:** Turn state deeply integrated with audio streaming

#### Turn-Aware Audio Pattern:

```typescript
// Audio automatically respects turn state when configured
const client = new RealtimeClient({
  audioConfig: {
    respectTurnState: true  // Critical: Prevents talk-over
  }
});

// useAudio hook provides turn-aware controls
const { 
  startStreaming,
  stopStreaming,
  canSendInput,    // Based on turn state
  status 
} = useAudio({ respectTurnState: true });

// Hook automatically stops streaming when losing turn
// No manual intervention needed
```

### 8. Message Handling & Text Accumulation

**Design Assumption:** Complete messages arrive from server  
**Reality:** Text streams in deltas, needs accumulation

#### Actual Message Flow:

```typescript
// Server sends these events for text:
1. text_delta     - Partial text chunks
2. completion     - Signals text is complete

// SessionManager (internal to SDK) handles accumulation:
private textAccumulator = '';

handleTextDelta(content: string) {
  this.textAccumulator += content;
  // Emit partial for live UI updates
}

handleCompletion() {
  // Add complete message to history
  this.addAssistantMessage(this.textAccumulator);
  this.textAccumulator = '';
}

// useChat hook provides clean interface:
const { messages, sendMessage } = useChat();
// messages array contains complete messages only
```

## Data Flow Diagrams

### Login → WebSocket Connection Flow

```
User Login
    ↓
Login API (/api/auth/login)
    ↓
Returns: {
  agent_c_token,
  ui_session_id,
  heygen_token,
  user_info,
  voices[],
  avatars[]
}
    ↓
Store tokens in cookies
    ↓
Navigate to Chat Page
    ↓
Initialize RealtimeClient with:
  - authToken (JWT)
  - sessionId (ui_session_id)
    ↓
client.connect()
    ↓
WebSocket established with auth
```

### Avatar Session Flow

```
User selects avatar mode
    ↓
Initialize HeyGen StreamingAvatar
    ↓
avatar.createStartAvatar()
    ↓
HeyGen: STREAM_READY event
    ↓
client.setAvatarSession(sessionId, avatarId)
    ↓
Agent C switches to avatar voice mode
    ↓
Audio routes through HeyGen (no PCM streaming)
```

## Component Build Priority

### Must Build Now (Core Functionality):

1. **Authentication Integration**
   
   ```typescript
   // lib/auth-context.tsx
   - Wraps auth.ts functions
   - Provides user info to components
   - Handles token refresh
   ```

2. **Client Initialization**
   
   ```typescript
   // components/ClientProvider.tsx
   - Initializes RealtimeClient with auth
   - Handles connection lifecycle
   - Provides client to child components
   ```

3. **Connection Management**
   
   ```typescript
   // components/ConnectionStatus.tsx
   - Uses useConnection() hook
   - Shows connection state
   - Retry connection button
   ```

### Already Built (Don't Recreate):

- `InputArea` - Complete with all controls
- `OutputSelector` - Exists in InputArea toolbar
- Audio controls - Part of InputArea
- Turn state visualization - In InputArea

### Stub for Later:

- Chat message rendering (complex formatting)
- Session history sidebar
- Voice visualizer (Three.js integration)
- Session renaming/management

## Correct Hook Usage Examples

### Connection Status Component

```typescript
const ConnectionStatus = () => {
  const { 
    isConnected, 
    connectionState, 
    error,
    stats,
    reconnect 
  } = useConnection();

  return (
    <div className="flex items-center gap-2">
      <div className={cn(
        "h-2 w-2 rounded-full",
        isConnected ? "bg-green-500" : "bg-red-500"
      )} />
      <span className="text-sm">
        {connectionState}
        {stats.sessionDuration > 0 && 
          ` (${Math.floor(stats.sessionDuration / 1000)}s)`
        }
      </span>
      {error && (
        <Button size="sm" onClick={reconnect}>
          Retry
        </Button>
      )}
    </div>
  );
};
```

### Audio Controls Component

```typescript
const AudioControls = () => {
  const { 
    startStreaming,
    stopStreaming,
    status,
    canSendInput 
  } = useAudio({ respectTurnState: true });

  return (
    <div className="flex items-center gap-2">
      <Button
        onClick={status.isStreaming ? stopStreaming : startStreaming}
        disabled={!canSendInput && !status.isStreaming}
      >
        {status.isStreaming ? <MicOff /> : <Mic />}
      </Button>
      {/* Audio level indicator */}
      <div className="h-1 w-20 bg-muted rounded">
        <div 
          className="h-full bg-primary transition-all"
          style={{ width: `${status.currentLevel * 100}%` }}
        />
      </div>
    </div>
  );
};
```

## Implementation Checklist

### ✅ What Already Exists in SDK:

- [x] WebSocket connection management
- [x] Binary audio protocol (PCM16)
- [x] Turn state management
- [x] Voice model switching
- [x] Avatar session coordination
- [x] Message accumulation from deltas
- [x] Reconnection with exponential backoff
- [x] Audio recording and streaming
- [x] React hooks for all features

### ❌ What Doesn't Exist (Needs Building):

- [ ] Authentication context/provider for React
- [ ] Chat message rendering components
- [ ] Session history UI
- [ ] Voice visualizer integration
- [ ] User preferences persistence
- [ ] Session search/filter UI

### ⚠️ Common Pitfalls to Avoid:

1. **Don't create a useAuth hook** - Auth is pre-SDK
2. **Don't manually handle text deltas** - useChat does this
3. **Don't manage turn state manually** - useAudio handles it
4. **Don't wrap binary audio in JSON** - Send raw ArrayBuffer
5. **Don't forget setAvatarSession** - Required for avatar mode
6. **Don't recreate InputArea** - It's complete and tested

## Testing Considerations

### Required Test Scenarios:

1. **Auth Token Expiry**
   
   ```typescript
   // Test reconnection with refreshed token
   authManager.on('auth:tokens-refreshed', (tokens) => {
     // SDK should auto-reconnect
   });
   ```

2. **Avatar Session Lifecycle**
   
   ```typescript
   // Test avatar initialization → session set → termination
   // Ensure voice mode switches correctly
   ```

3. **Turn State Transitions**
   
   ```typescript
   // Test audio stops when losing turn
   // Test UI updates reflect turn state
   ```

4. **Message Accumulation**
   
   ```typescript
   // Test partial text updates
   // Test completion creates full message
   ```

## Summary of Key Technical Points

1. **Authentication is external to SDK** - Handle login first, then initialize SDK
2. **ui_session_id comes from login** - Not created by SDK
3. **Avatar requires explicit session notification** - Call setAvatarSession after HeyGen ready
4. **Turn management is automatic** - Configure respectTurnState, SDK handles the rest
5. **Messages stream as deltas** - SDK accumulates, useChat provides complete messages
6. **Voice modes affect routing** - 'none' = text only, 'avatar' = HeyGen handles audio
7. **Binary audio is raw PCM16** - Not wrapped in JSON events
8. **InputArea is complete** - Don't recreate, just integrate

## Next Steps for Implementation

1. **Create auth context provider** wrapping auth.ts functions
2. **Build ClientProvider** to initialize SDK with auth
3. **Implement ChatLayout** with correct component hierarchy
4. **Wire up existing InputArea** - Already has OutputSelector
5. **Create placeholder views** for chat/avatar/voice modes
6. **Test connection flow** from login → WebSocket
7. **Verify turn state** affects audio streaming
8. **Test avatar session** lifecycle

This technical addendum ensures the chat interface implementation aligns with the actual SDK architecture and capabilities. Follow these patterns for successful integration.